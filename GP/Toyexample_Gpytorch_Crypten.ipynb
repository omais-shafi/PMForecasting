{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0011b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gpytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cf1c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import gpytorch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from gpytorch.variational import CholeskyVariationalDistribution, VariationalStrategy\n",
    "from gpytorch.models import ApproximateGP\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9d08e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import crypten\n",
    "# import crypten.communicator as comm\n",
    "# crypten.init()\n",
    "# torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5458ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dde263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPModel(ApproximateGP):\n",
    "    def __init__(self, inducing_points):\n",
    "      \"\"\"\n",
    "      This initializes the model with some standard settings including the variational distribution to be used, the number of inducing points\n",
    "      being used along with the mean and the covariance functions being used. \n",
    "\n",
    "      Below ConstantMean refers to the Mean being a constant. This means that the mean learnt will act as an offset of sorts whereas all the \n",
    "      variance in the data will be explained by the covariance function. The Mean can also be set to linear where it becomes a linear function\n",
    "      of the features. \n",
    "\n",
    "      A basic RBF kernel has been used here that learns one lengthscale for all the dimensions. ScaleKernel below just imbues the RBF Kernel\n",
    "      with a scalar scale value that can scale the value of the RBF kernel. \n",
    "      \"\"\"\n",
    "      variational_distribution = CholeskyVariationalDistribution(inducing_points.size(0))\n",
    "      variational_strategy = VariationalStrategy(self, inducing_points, variational_distribution, learn_inducing_locations=True)\n",
    "      super(GPModel, self).__init__(variational_strategy)\n",
    "      self.mean_module = gpytorch.means.ConstantMean()\n",
    "      self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "      \"\"\"\n",
    "      This is akin to the forward pass in Neural Nets in a way. Here the mean and the covariance functions are calculated on some given x.\n",
    "      Then, using that mean and covariance function, a MultivariateNormal distribtuion is represented. \n",
    "      \"\"\"\n",
    "      mean_x = self.mean_module(x)\n",
    "      covar_x = self.covar_module(x)\n",
    "      temp = gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "      return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de68446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALICE = 0\n",
    "BOB = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5a1f9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = list(range(1000))\n",
    "n= len(cities)\n",
    "data = {'Temperature': np.random.normal(24, 3, n),\n",
    "        'Humidity': np.random.normal(78, 2.5, n),\n",
    "       }\n",
    "df = pd.DataFrame(data=data, index=cities)\n",
    "df[\"Wind\"] = df.Temperature + df.Humidity + np.random.normal(0, 0.1, n) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1620459",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = df[[\"Temperature\", \"Humidity\"]].values\n",
    "train_y = df.Wind.values\n",
    "train_x, train_y = torch.Tensor(train_x), torch.Tensor(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47f5f7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to share this?\n",
    "inducing_points = train_x[:500, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1753318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_x, train_y) \n",
    "train_loader = DataLoader(train_dataset, batch_size=200, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e7d2159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GPModel(inducing_points=inducing_points)\n",
    "# # The likelihood is learnt separate from the model. This refers to the epsilon/error term in the GP model formulation. \n",
    "# likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "# # Below checks if the cuda/GPU is avaliable or not. If it is, then the model and likelihood both are transferred to the GPU\n",
    "# if torch.cuda.is_available():\n",
    "#     model = model.cuda()\n",
    "#     likelihood = likelihood.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98cec46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now we set both to training mode\n",
    "# model.train()\n",
    "# likelihood.train()\n",
    "\n",
    "# # The use of an optimizer is again very similar to how it is used in neural nets. lr is learning rate.\n",
    "# optimizer = torch.optim.Adam([\n",
    "#     {'params': model.parameters()},\n",
    "#     {'params': likelihood.parameters()},\n",
    "# ], lr=0.05)\n",
    "\n",
    "# # Our loss object. We're using the VariationalELBO. This defines the loss function we are trying to optimize\n",
    "# mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=train_y.size(0))\n",
    "\n",
    "# num_epochs = 500                  ############ please change this if you want to increase or decrease train time ############ \n",
    "# for i in range(num_epochs):\n",
    "#     count = 0\n",
    "#     mean_loss = 0\n",
    "#     # Within each iteration, we will go over each minibatch of data\n",
    "#     minibatch_iter = train_loader\n",
    "#     for x_batch, y_batch in minibatch_iter:\n",
    "        \n",
    "#         output = model(x_batch)\n",
    "#         loss = -mll(output, y_batch)\n",
    "#         print(type(loss))\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "# #         print(loss)\n",
    "#         optimizer.step()\n",
    "#         mean_loss += loss.item()\n",
    "#         count+=1\n",
    "#     if i%10 == 0:\n",
    "#       print(\"Mean Loss for Epoch\", i,\":\", mean_loss/count)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e2abff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now we set both to training mode\n",
    "# model.train()\n",
    "# likelihood.train()\n",
    "\n",
    "# # The use of an optimizer is again very similar to how it is used in neural nets. lr is learning rate.\n",
    "# optimizer = torch.optim.Adam([\n",
    "#     {'params': model.parameters()},\n",
    "#     {'params': likelihood.parameters()},\n",
    "# ], lr=0.05)\n",
    "\n",
    "# # Our loss object. We're using the VariationalELBO. This defines the loss function we are trying to optimize\n",
    "# mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=train_y.size(0))\n",
    "# num_epochs = 500                  ############ please change this if you want to increase or decrease train time ############ \n",
    "# epochs_iter = range(num_epochs)\n",
    "\n",
    "# # Define training parameters\n",
    "# learning_rate = 0.001\n",
    "# # num_epochs = 2\n",
    "# batch_size = 200\n",
    "# num_batches = train_x.size(0) // batch_size\n",
    "\n",
    "# for i in range(num_epochs): \n",
    "#     print(f\"Epoch {i} in progress:\")       \n",
    "\n",
    "#     for batch in range(num_batches):\n",
    "#         # define the start and end of the training mini-batch\n",
    "#         start, end = batch * batch_size, (batch + 1) * batch_size\n",
    "\n",
    "#         # construct CrypTensors out of training examples / labels\n",
    "#         x_train_ep = train_x[start:end]\n",
    "#         y_train_ep = train_y[start:end]\n",
    "# #         y_train = crypten.cryptensor(y_batch, requires_grad=True)\n",
    "\n",
    "#         # perform forward pass:\n",
    "#         output = model.forward(x_train_ep)\n",
    "#         loss_value = -mll(output, y_train_ep)\n",
    "\n",
    "# #         set gradients to \"zero\" \n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # perform backward pass: \n",
    "#         loss_value.backward(retain_graph=True)\n",
    "\n",
    "#         # update parameters\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # Print progress every batch:\n",
    "#         batch_loss = loss_value\n",
    "#         print(f\"\\tBatch {(batch + 1)} of {num_batches} Loss {batch_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a800bed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import crypten\n",
    "import crypten.communicator as comm\n",
    "crypten.init()\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf96278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "from gpytorch.variational import CholeskyVariationalDistribution, VariationalStrategy\n",
    "from gpytorch.models import ApproximateGP\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.mlls import VariationalELBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be00cd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_enc = crypten.cryptensor(train_x, src=ALICE, requires_grad=True)\n",
    "train_y_enc = crypten.cryptensor(train_y, src=ALICE, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e5678d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_x.dim())\n",
    "# print(train_x[0].shape)model_plaintext = GPModel(inducing_points=inducing_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2342fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This doesn't work\n",
    "# model = crypten.nn.from_pytorch(model_plaintext, torch.empty((1, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12bdd0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrypTenModel2(ApproximateGP):\n",
    "    def __init__(self, inducing_points):\n",
    "#         super(CrypTenModel2, self).__init__()\n",
    "        crypten.nn.Module.__init__(self)\n",
    "        variational_distribution = CholeskyVariationalDistribution(inducing_points.size(0))\n",
    "        variational_strategy = VariationalStrategy(self, inducing_points, variational_distribution, learn_inducing_locations=True)\n",
    "        ApproximateGP.__init__(self, variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "#         print(type(x))\n",
    "        mean_x = self.mean_module(x)\n",
    "#         print(type(mean_x))\n",
    "#         print(type(x))\n",
    "#         mean_x_enc = crypten.cryptensor(mean_x)\n",
    "        covar_x = self.covar_module(x)\n",
    "#         print(type(covar_x))\n",
    "#         x_enc = crypten.cryptensor(x)\n",
    "#         mean_x_enc = self.mean_module(x_enc)\n",
    "#         covar_x_enc = self.covar_module(x_enc)\n",
    "#         print(type(covar_x))\n",
    "#         print(type(covar_x_enc))\n",
    "        temp = gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "        return temp\n",
    "    \n",
    "#     def __call__(self, inputs, prior=False, **kwargs):\n",
    "#         if inputs.dim() == 1:\n",
    "#             inputs = inputs.unsqueeze(-1)\n",
    "#         return self.variational_strategy(inputs, prior=prior, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7cd55d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Likelihood_crypten(GaussianLikelihood):\n",
    "#     def __init__(self):\n",
    "# #         super(CrypTenModel2, self).__init__()\n",
    "# #         crypten.nn.Module.__init__(self)\n",
    "#         GaussianLikelihood.__init__(self)\n",
    "        \n",
    "class loss_crypten(VariationalELBO):\n",
    "    def __init__(self):\n",
    "#         super(CrypTenModel2, self).__init__()\n",
    "#         crypten.nn.Module.__init__(self)\n",
    "        VariationalELBO.__init__(self, likelihood, model, num_data=train_y.size(0))\n",
    "    def forward(self, variational_dist_f, target, **kwargs):\n",
    "        loss = VariationalELBO.forward(self, variational_dist_f, target, **kwargs)\n",
    "#         loss_enc = crypten.cryptensor(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6920a4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inducing_points_enc = crypten.cryptensor(inducing_points, src=ALICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ea0217f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name variational_params_initialized\n",
      "buffer tensor(0)\n",
      "name updated_strategy\n",
      "buffer tensor(1.)\n",
      "name active_dims\n",
      "buffer None\n",
      "name active_dims\n",
      "buffer None\n"
     ]
    }
   ],
   "source": [
    "model = CrypTenModel2(inducing_points)\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "# likelihood = Likelihood_crypten()\n",
    "mll = loss_crypten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4af2842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_crypten unencrypted module"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we set both to training mode\n",
    "model.train()\n",
    "likelihood.train()\n",
    "mll.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df5fd5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VariationalStrategy unencrypted module\n",
      "tensor(0)\n",
      "tensor(1.)\n",
      "ConstantMean unencrypted module\n",
      "ScaleKernel unencrypted module\n",
      "None\n",
      "None\n",
      "HomoskedasticNoise unencrypted module\n",
      "GreaterThan(1.000E-04)\n",
      "GreaterThan(1.000E-04)\n",
      "GaussianLikelihood encrypted module\n",
      "HomoskedasticNoise encrypted module\n",
      "GreaterThan(1.000E-04)\n",
      "CrypTenModel2 encrypted module\n",
      "VariationalStrategy encrypted module\n",
      "ConstantMean encrypted module\n",
      "ScaleKernel encrypted module\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "loss_crypten encrypted module"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encrypt()\n",
    "# print(type(likelihood))\n",
    "likelihood.encrypt()\n",
    "mll.encrypt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29a4cb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(model.encrypted)\n",
    "print(likelihood.encrypted)\n",
    "print(mll.encrypted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eddc3c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultivariateNormal(loc: torch.Size([1000]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is MultivariateNormal encrypted?\n",
    "model.forward(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5227f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make this crypten?\n",
    "# likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "# print(type(likelihood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "137e9d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaced x.ndimension() to x.dim() in gpytorch library as MPC Tensor does not support .ndimension but .dim() is an alias of it\n",
    "# not able to encrypt the covraince because a lot of boolean expressions are used, which are encrypted in cryptensor and cannot be\n",
    "# evaluated before converting them to plaintext\n",
    "# MPC Tensor when converted to Lazy Tensor has type changed to Lazt Tensor\n",
    "# line 46 gaussian_likelihood.py\n",
    "# liene 61, 69 _approximate_mll.py\n",
    "# line 19 mean.py\n",
    "# line 300-302, 322, 369, 372 kernel.py\n",
    "# line 456 module.py\n",
    "# line 270 lazy_evaluated_kernal_tensor.py\n",
    "# line 2242 lazy_tensor.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea9f63ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# The use of an optimizer is again very similar to how it is used in neural nets. lr is learning rate.\n",
    "# optimizer = torch.optim.Adam([\n",
    "#     {'params': model.parameters()},\n",
    "#     {'params': likelihood.parameters()},\n",
    "# ], lr=0.05)\n",
    "crypten_optimizer = crypten.optim.SGD([\n",
    "    {'params': model.parameters()},\n",
    "    {'params': likelihood.parameters()},\n",
    "], lr=0.05)\n",
    "# mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=train_y.size(0))\n",
    "# print(type(mll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2be0e5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n",
      "torch.int64\n",
      "var torch.float32\n",
      "torch.float32\n",
      "MPCTensor(\n",
      "\t_tensor=0\n",
      "\tplain_text=HIDDEN\n",
      "\tptype=ptype.arithmetic\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Autograd is not supported for in-place functions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_161/1810649232.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0my_batch_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrypten\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcryptensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mALICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mcrypten_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;31m#         output_enc = crypten.cryptensor(output, src=ALICE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/gauri/Desktop/sem9/MTP/gpytorch/gpytorch/models/approximate_gp.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, prior, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariational_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/c/Users/gauri/Desktop/sem9/MTP/gpytorch/gpytorch/variational/variational_strategy.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, prior, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdated_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply_enc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/gauri/Desktop/sem9/MTP/gpytorch/gpytorch/variational/_variational_strategy.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, prior, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0minducing_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariational_dist_u\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0mvariational_inducing_covar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariational_dist_u\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_covariance_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m             )\n\u001b[1;32m    133\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariational_dist_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/gauri/Desktop/sem9/MTP/gpytorch/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/gauri/Desktop/sem9/MTP/CrypTen/crypten/nn/module.py\u001b[0m in \u001b[0;36mforward_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m                         \u001b[0;34m\"Encrypt the model before feeding it CrypTensors.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m                     )\n\u001b[0;32m--> 538\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mforward_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/gauri/Desktop/sem9/MTP/gpytorch/gpytorch/variational/variational_strategy.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, inducing_points, inducing_values, variational_inducing_covar, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mnum_induc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minducing_points\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mtest_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_induc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0minduc_induc_covar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_covar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mnum_induc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mnum_induc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_jitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0minduc_data_covar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_covar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mnum_induc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_induc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mdata_data_covar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_covar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_induc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_induc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/gauri/Desktop/sem9/MTP/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\u001b[0m in \u001b[0;36madd_jitter\u001b[0;34m(self, jitter_val)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_jitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjitter_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_jitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjitter_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_unsqueeze_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/gauri/Desktop/sem9/MTP/gpytorch/gpytorch/utils/memoize.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mkwargs_pkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_in_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_add_to_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/gauri/Desktop/sem9/MTP/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\u001b[0m in \u001b[0;36mevaluate_kernel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mtemp_active_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_active_dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/gauri/Desktop/sem9/MTP/gpytorch/gpytorch/kernels/kernel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[1;32m    414\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLazyEvaluatedKernelTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlazify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/gauri/Desktop/sem9/MTP/gpytorch/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/gauri/Desktop/sem9/MTP/CrypTen/crypten/nn/module.py\u001b[0m in \u001b[0;36mforward_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m                         \u001b[0;34m\"Encrypt the model before feeding it CrypTensors.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m                     )\n\u001b[0;32m--> 538\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mforward_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/gauri/Desktop/sem9/MTP/gpytorch/gpytorch/kernels/scale_kernel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, last_dim_is_batch, diag, **params)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0morig_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_kernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0moutputscales\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/gauri/Desktop/sem9/MTP/CrypTen/crypten/nn/module.py\u001b[0m in \u001b[0;36mforward_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m                         \u001b[0;34m\"Encrypt the model before feeding it CrypTensors.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m                     )\n\u001b[0;32m--> 538\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mforward_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/gauri/Desktop/sem9/MTP/gpytorch/gpytorch/kernels/rbf_kernel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, diag, **params)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlengthscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             lambda x1, x2: self.covar_dist(\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquare_dist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist_postprocess_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpostprocess_rbf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             ),\n",
      "\u001b[0;32m/mnt/c/Users/gauri/Desktop/sem9/MTP/gpytorch/gpytorch/functions/rbf_covariance.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, x1, x2, lengthscale, sq_dist_func)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx1_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengthscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx2_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengthscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0munitless_sq_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msq_dist_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m# clone because inplace operations will mess with what's saved for backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0munitless_sq_dist_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munitless_sq_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mneeds_grad\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0munitless_sq_dist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/gauri/Desktop/sem9/MTP/gpytorch/gpytorch/kernels/rbf_kernel.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlengthscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             lambda x1, x2: self.covar_dist(\n\u001b[0;32m---> 91\u001b[0;31m                 \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquare_dist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist_postprocess_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpostprocess_rbf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m             ),\n\u001b[1;32m     93\u001b[0m         )\n",
      "\u001b[0;32m/mnt/c/Users/gauri/Desktop/sem9/MTP/gpytorch/gpytorch/kernels/kernel.py\u001b[0m in \u001b[0;36mcovar_dist\u001b[0;34m(self, x1, x2, diag, last_dim_is_batch, square_dist, dist_postprocess_func, postprocess, **params)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msquare_dist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sq_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1_eq_x2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1_eq_x2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/gauri/Desktop/sem9/MTP/gpytorch/gpytorch/kernels/kernel.py\u001b[0m in \u001b[0;36m_sq_dist\u001b[0;34m(self, x1, x2, postprocess, x1_eq_x2)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Zero out negative values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp_min_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_postprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpostprocess\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/gauri/Desktop/sem9/MTP/CrypTen/crypten/debug/__init__.py\u001b[0m in \u001b[0;36mvalidate_attribute\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidate_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Get dispatched function call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mfunction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/gauri/Desktop/sem9/MTP/CrypTen/crypten/cryptensor.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mCrypTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOGRAD_ENABLED\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Autograd is not supported for in-place functions.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0;31m# Note: native in-place support is now deprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Autograd is not supported for in-place functions."
     ]
    }
   ],
   "source": [
    "# Now we set both to training mode\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# The use of an optimizer is again very similar to how it is used in neural nets. lr is learning rate.\n",
    "# optimizer = torch.optim.Adam([\n",
    "#     {'params': model.parameters()},\n",
    "#     {'params': likelihood.parameters()},\n",
    "# ], lr=0.05)\n",
    "crypten_optimizer = crypten.optim.SGD([\n",
    "    {'params': model.parameters()},\n",
    "    {'params': likelihood.parameters()},\n",
    "], lr=0.05)\n",
    "# Our loss object. We're using the VariationalELBO. This defines the loss function we are trying to optimize\n",
    "# mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=train_y.size(0))\n",
    "\n",
    "num_epochs = 500                  ############ please change this if you want to increase or decrease train time ############ \n",
    "for i in range(num_epochs):\n",
    "    count = 0\n",
    "    mean_loss = 0\n",
    "    # Within each iteration, we will go over each minibatch of data\n",
    "    minibatch_iter = train_loader\n",
    "    for x_batch, y_batch in minibatch_iter:\n",
    "        x_batch_enc = crypten.cryptensor(x_batch, src=ALICE)\n",
    "        y_batch_enc = crypten.cryptensor(y_batch, src=ALICE)\n",
    "        crypten_optimizer.zero_grad()\n",
    "        output = model(x_batch_enc)\n",
    "#         output_enc = crypten.cryptensor(output, src=ALICE)\n",
    "        print('output', type(output))\n",
    "        print('y_batch', type(y_batch))\n",
    "        loss = -mll(output, y_batch_enc)\n",
    "        print('loss', type(loss))\n",
    "        loss.backward()\n",
    "        crypten_optimizer.step()\n",
    "        batch_loss = loss.get_plain_text()\n",
    "        count+=1\n",
    "        crypten.print(f\"Loss {batch_loss.item():.4f}\")\n",
    "#     if i%10 == 0:\n",
    "#       print(\"Mean Loss for Epoch\", i,\":\", mean_loss/count)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f96715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now we set both to training mode\n",
    "# model.train()\n",
    "# likelihood.train()\n",
    "\n",
    "# # The use of an optimizer is again very similar to how it is used in neural nets. lr is learning rate.\n",
    "# optimizer = torch.optim.Adam([\n",
    "#     {'params': model.parameters()},\n",
    "#     {'params': likelihood.parameters()},\n",
    "# ], lr=0.05)\n",
    "\n",
    "# # Our loss object. We're using the VariationalELBO. This defines the loss function we are trying to optimize\n",
    "# mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data = train_y_enc.size(0))\n",
    "# num_epochs = 500                  ############ please change this if you want to increase or decrease train time ############ \n",
    "# epochs_iter = range(num_epochs)\n",
    "\n",
    "# # Define training parameters\n",
    "# learning_rate = 0.001\n",
    "# # num_epochs = 2\n",
    "# batch_size = 200\n",
    "# num_batches = train_x_enc.size(0) // batch_size\n",
    "\n",
    "# rank = comm.get().get_rank()\n",
    "# for i in range(num_epochs): \n",
    "#     crypten.print(f\"Epoch {i} in progress:\")       \n",
    "\n",
    "#     for batch in range(num_batches):\n",
    "#         # define the start and end of the training mini-batch\n",
    "#         start, end = batch * batch_size, (batch + 1) * batch_size\n",
    "\n",
    "#         # construct CrypTensors out of training examples / labels\n",
    "#         x_train_ep = train_x_enc[start:end]\n",
    "#         y_train_ep = train_y_enc[start:end]\n",
    "# #         y_train = crypten.cryptensor(y_batch, requires_grad=True)\n",
    "\n",
    "#         # perform forward pass:\n",
    "#         output = model.forward(x_train_ep)\n",
    "#         loss_value = -mll(output, y_train_ep)\n",
    "\n",
    "# #         set gradients to \"zero\" (use any)\n",
    "#         model.zero_grad()\n",
    "# #         optimizer.zero_grad()\n",
    "\n",
    "#         # perform backward pass: \n",
    "#         loss_value.backward()\n",
    "\n",
    "#         # update parameters (use any)\n",
    "#         model.update_parameters(learning_rate)\n",
    "# #         optimizer.step()\n",
    "\n",
    "#         # Print progress every batch:\n",
    "#         batch_loss = loss_value.get_plain_text()\n",
    "#         crypten.print(f\"\\tBatch {(batch + 1)} of {num_batches} Loss {batch_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac11815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.decrypt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5b867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_enc = crypten.cryptensor([1.0, 2.0, 3.0], [1.0, 2.0, 3.0])\n",
    "y_enc = crypten.cryptensor([4.0, 5.0, 6.0], [4.0, 5.0, 6.0])\n",
    "\n",
    "\n",
    "# Concatenation\n",
    "\n",
    "z_enc = crypten.cat([x_enc, y_enc])\n",
    "z_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52c5698",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_enc.cat([x_enc, y_enc, x_enc]).get_plain_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b7999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_enc.get_plain_text()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
